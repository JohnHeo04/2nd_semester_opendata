{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "monkey_classifier",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnHeo04/2nd_semester_opendata/blob/master/monkey_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUwdlVCZxIkM",
        "colab_type": "code",
        "outputId": "db4ccb21-9b69-4eac-d932-456d9a60ba87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-rxJ_Tiw9Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import h5py\n",
        "import shutil\n",
        "import imgaug as aug\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import imgaug.augmenters as iaa\n",
        "from os import listdir, makedirs, getcwd, remove\n",
        "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
        "from pathlib import Path\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "color = sns.color_palette()\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format=\"svg\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRYq4wb7nuzM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "4e24be31-1bf7-4bfc-b37c-48e98ae0aebd"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1orObuG-jbnh",
        "colab_type": "text"
      },
      "source": [
        "### 3.Load dataset and process it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H39nOTrlhtRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "seed=1234\n",
        "\n",
        "# Set the numpy seed\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Set the random seed in tensorflow at graph level\n",
        "tf.set_random_seed(seed)\n",
        "\n",
        "# Make the augmentation sequence deterministic\n",
        "aug.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqb10XswhtOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = Path('/content/drive/My Drive/animal_classification/monkey/training/') \n",
        "validation_data = Path('/content/drive/My Drive/animal_classification/monkey/validation/') \n",
        "labels_path = Path('/content/drive/My Drive/animal_classification/monkey/monkey_labels.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr63Nk0JhtMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "d16e6289-ce5c-4d82-8f88-8005077913e8"
      },
      "source": [
        "labels_info = []\n",
        "\n",
        "# Read the file\n",
        "lines = labels_path.read_text().strip().splitlines()[1:]\n",
        "for line in lines:\n",
        "    line = line.split(',')\n",
        "    line = [x.strip(' \\n\\t\\r') for x in line]\n",
        "    line[3], line[4] = int(line[3]), int(line[4])\n",
        "    line = tuple(line)\n",
        "    labels_info.append(line)\n",
        "    \n",
        "# Convert the data into a pandas dataframe\n",
        "labels_info = pd.DataFrame(labels_info, columns=['Label', 'Latin Name', 'Common Name', \n",
        "                                                 'Train Images', 'Validation Images'], index=None)\n",
        "# Sneak peek \n",
        "labels_info.head(10)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Latin Name</th>\n",
              "      <th>Common Name</th>\n",
              "      <th>Train Images</th>\n",
              "      <th>Validation Images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>n0</td>\n",
              "      <td>alouatta_palliata</td>\n",
              "      <td>mantled_howler</td>\n",
              "      <td>131</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>n1</td>\n",
              "      <td>erythrocebus_patas</td>\n",
              "      <td>patas_monkey</td>\n",
              "      <td>139</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>n2</td>\n",
              "      <td>cacajao_calvus</td>\n",
              "      <td>bald_uakari</td>\n",
              "      <td>137</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>n3</td>\n",
              "      <td>macaca_fuscata</td>\n",
              "      <td>japanese_macaque</td>\n",
              "      <td>152</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>n4</td>\n",
              "      <td>cebuella_pygmea</td>\n",
              "      <td>pygmy_marmoset</td>\n",
              "      <td>131</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>n5</td>\n",
              "      <td>cebus_capucinus</td>\n",
              "      <td>white_headed_capuchin</td>\n",
              "      <td>141</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>n6</td>\n",
              "      <td>mico_argentatus</td>\n",
              "      <td>silvery_marmoset</td>\n",
              "      <td>132</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>n7</td>\n",
              "      <td>saimiri_sciureus</td>\n",
              "      <td>common_squirrel_monkey</td>\n",
              "      <td>142</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>n8</td>\n",
              "      <td>aotus_nigriceps</td>\n",
              "      <td>black_headed_night_monkey</td>\n",
              "      <td>133</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>n9</td>\n",
              "      <td>trachypithecus_johnii</td>\n",
              "      <td>nilgiri_langur</td>\n",
              "      <td>132</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Label             Latin Name  ... Train Images  Validation Images\n",
              "0    n0      alouatta_palliata  ...          131                 26\n",
              "1    n1     erythrocebus_patas  ...          139                 28\n",
              "2    n2         cacajao_calvus  ...          137                 27\n",
              "3    n3         macaca_fuscata  ...          152                 30\n",
              "4    n4        cebuella_pygmea  ...          131                 26\n",
              "5    n5        cebus_capucinus  ...          141                 28\n",
              "6    n6        mico_argentatus  ...          132                 26\n",
              "7    n7       saimiri_sciureus  ...          142                 28\n",
              "8    n8        aotus_nigriceps  ...          133                 27\n",
              "9    n9  trachypithecus_johnii  ...          132                 26\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh3yK-AJhtKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "627d3369-78c1-4bdf-d41f-3ca9f8c7ad57"
      },
      "source": [
        "# Create a dictionary to map the labels to integers\n",
        "labels_dict= {'n0':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'n5':5, 'n6':6, 'n7':7, 'n8':8, 'n9':9}\n",
        "\n",
        "# map labels to common names\n",
        "names_dict = dict(zip(labels_dict.values(), labels_info[\"Common Name\"]))\n",
        "print(names_dict)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'mantled_howler', 1: 'patas_monkey', 2: 'bald_uakari', 3: 'japanese_macaque', 4: 'pygmy_marmoset', 5: 'white_headed_capuchin', 6: 'silvery_marmoset', 7: 'common_squirrel_monkey', 8: 'black_headed_night_monkey', 9: 'nilgiri_langur'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNvY03D8htFd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "a7bf11f5-8bfb-4230-9041-c4af6ecf843f"
      },
      "source": [
        "# Creating a dataframe for the training dataset\n",
        "train_df = []\n",
        "for folder in os.listdir(training_data):\n",
        "    # Define the path to the images\n",
        "    imgs_path = training_data / folder\n",
        "    \n",
        "    # Get the list of all the images stored in that directory\n",
        "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
        "    \n",
        "    # Store each image path and corresponding label \n",
        "    for img_name in imgs:\n",
        "        train_df.append((str(img_name), labels_dict[folder]))\n",
        "\n",
        "\n",
        "train_df = pd.DataFrame(train_df, columns=['image', 'label'], index=None)\n",
        "# shuffle the dataset \n",
        "train_df = train_df.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "####################################################################################################\n",
        "\n",
        "# Creating dataframe for validation data in a similar fashion\n",
        "valid_df = []\n",
        "for folder in os.listdir(validation_data):\n",
        "    imgs_path = validation_data / folder\n",
        "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
        "    for img_name in imgs:\n",
        "        valid_df.append((str(img_name), labels_dict[folder]))\n",
        "\n",
        "        \n",
        "valid_df = pd.DataFrame(valid_df, columns=['image', 'label'], index=None)\n",
        "# shuffle the dataset \n",
        "valid_df = valid_df.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "####################################################################################################\n",
        "\n",
        "# How many samples do we have in our training and validation data?\n",
        "print(\"Number of traininng samples: \", len(train_df))\n",
        "print(\"Number of validation samples: \", len(valid_df))\n",
        "\n",
        "# sneak peek of the training and validation dataframes\n",
        "print(\"\\n\",train_df.head(), \"\\n\")\n",
        "print(\"=================================================================\\n\")\n",
        "print(\"\\n\", valid_df.head())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of traininng samples:  0\n",
            "Number of validation samples:  0\n",
            "\n",
            " Empty DataFrame\n",
            "Columns: [image, label]\n",
            "Index: [] \n",
            "\n",
            "=================================================================\n",
            "\n",
            "\n",
            " Empty DataFrame\n",
            "Columns: [image, label]\n",
            "Index: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXLVVytthtD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some constants(not truly though!) \n",
        "\n",
        "# dimensions to consider for the images\n",
        "img_rows, img_cols, img_channels = 224,224,3\n",
        "\n",
        "# batch size for training  \n",
        "batch_size=8\n",
        "\n",
        "# total number of classes in the dataset\n",
        "nb_classes=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGvwkQN0l-I5",
        "colab_type": "text"
      },
      "source": [
        "### 4.Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHYxTvsWhtBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Augmentation sequence \n",
        "seq = iaa.OneOf([\n",
        "    iaa.Fliplr(), # horizontal flips\n",
        "    iaa.Affine(rotate=20), # roatation\n",
        "    iaa.Multiply((1.2, 1.5))]) #random brightness"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snCyUpzymt80",
        "colab_type": "text"
      },
      "source": [
        "### 5.Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2DHvVhzhs-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(data, batch_size, is_validation_data=False):\n",
        "    # Get total number of samples in the data\n",
        "    n = len(data)\n",
        "    nb_batches = int(np.ceil(n/batch_size))\n",
        "\n",
        "    # Get a numpy array of all the indices of the input data\n",
        "    indices = np.arange(n)\n",
        "    \n",
        "    # Define two numpy arrays for containing batch data and labels\n",
        "    batch_data = np.zeros((batch_size, img_rows, img_cols, img_channels), dtype=np.float32)\n",
        "    batch_labels = np.zeros((batch_size, nb_classes), dtype=np.float32)\n",
        "    \n",
        "    while True:\n",
        "        if not is_validation_data:\n",
        "            # shuffle indices for the training data\n",
        "            np.random.shuffle(indices)\n",
        "            \n",
        "        for i in range(nb_batches):\n",
        "            # get the next batch \n",
        "            next_batch_indices = indices[i*batch_size:(i+1)*batch_size]\n",
        "            \n",
        "            # process the next batch\n",
        "            for j, idx in enumerate(next_batch_indices):\n",
        "                img = cv2.imread(data.iloc[idx][\"image\"])\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                label = data.iloc[idx][\"label\"]\n",
        "                \n",
        "                if not is_validation_data:\n",
        "                    img = seq.augment_image(img)\n",
        "                \n",
        "                img = cv2.resize(img, (img_rows, img_cols)).astype(np.float32)\n",
        "                batch_data[j] = img\n",
        "                batch_labels[j] = to_categorical(label,num_classes=nb_classes)\n",
        "            \n",
        "            batch_data = preprocess_input(batch_data)\n",
        "            yield batch_data, batch_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wos686xwhs83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training data generator \n",
        "train_data_gen = data_generator(train_df, batch_size)\n",
        "\n",
        "# validation data generator \n",
        "valid_data_gen = data_generator(valid_df, batch_size, is_validation_data=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JiHTiWCm4pB",
        "colab_type": "text"
      },
      "source": [
        "### 6.Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK3Q_LKkhs6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# simple function that returns the base model\n",
        "def get_base_model():\n",
        "    base_model = VGG16(input_shape=(img_rows, img_cols, img_channels), weights='imagenet', include_top=True)\n",
        "    return base_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfmQY1XKhs4f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f512bf04-3509-4493-e053-272666b9f7a5"
      },
      "source": [
        "# get the base model\n",
        "base_model = get_base_model()\n",
        "\n",
        "#  get the output of the second last dense layer \n",
        "base_model_output = base_model.layers[-2].output\n",
        "\n",
        "# add new layers \n",
        "x = Dropout(0.7,name='drop2')(base_model_output)\n",
        "output = Dense(10, activation='softmax', name='fc3')(x)\n",
        "\n",
        "# define a new model \n",
        "model = Model(base_model.input, output)\n",
        "\n",
        "# Freeze all the base model layers \n",
        "for layer in base_model.layers[:-1]:\n",
        "    layer.trainable=False\n",
        "\n",
        "# compile the model and check it \n",
        "optimizer = RMSprop(0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 6s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "drop2 (Dropout)              (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "fc3 (Dense)                  (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 134,301,514\n",
            "Trainable params: 40,970\n",
            "Non-trainable params: 134,260,544\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTLOmXn6hs1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# always user earlystopping\n",
        "# the restore_best_weights parameter load the weights of the best iteration once the training finishes\n",
        "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "# checkpoint to save model\n",
        "chkpt = ModelCheckpoint(filepath=\"model1\", save_best_only=True)\n",
        "\n",
        "# number of training and validation steps for training and validation\n",
        "nb_train_steps = int(np.ceil(len(train_df)/batch_size))\n",
        "nb_valid_steps = int(np.ceil(len(valid_df)/batch_size))\n",
        "\n",
        "# number of epochs \n",
        "nb_epochs=100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fM9GnBqhs0B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "158a806c-0094-4dc7-bf94-0d9e53ac6098"
      },
      "source": [
        "# train the model \n",
        "history1 = model.fit_generator(train_data_gen, \n",
        "                              epochs=nb_epochs, \n",
        "                              steps_per_epoch=nb_train_steps, \n",
        "                              validation_data=valid_data_gen, \n",
        "                              validation_steps=nb_valid_steps,\n",
        "                              callbacks=[es,chkpt])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-fbb3bffffdef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_valid_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                               callbacks=[es,chkpt])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m     69\u001b[0m     if (val_gen and not val_use_sequence_api and\n\u001b[1;32m     70\u001b[0m             not validation_steps):\n\u001b[0;32m---> 71\u001b[0;31m         raise ValueError('`validation_steps=None` is only valid for a'\n\u001b[0m\u001b[1;32m     72\u001b[0m                          \u001b[0;34m' generator based on the `keras.utils.Sequence`'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                          \u001b[0;34m' class. Please specify `validation_steps` or use'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: `validation_steps=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `validation_steps` or use the `keras.utils.Sequence` class."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2HFbknlhsyT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "33d10f42-b5ad-422a-ec6b-5be56a91efb6"
      },
      "source": [
        " let's plot the loss and accuracy \n",
        "\n",
        "# get the training and validation accuracy from the history object\n",
        "train_acc = history1.history['acc']\n",
        "valid_acc = history1.history['val_acc']\n",
        "\n",
        "# get the loss\n",
        "train_loss = history1.history['loss']\n",
        "valid_loss = history1.history['val_loss']\n",
        "\n",
        "# get the number of entries\n",
        "xvalues = np.arange(len(train_acc))\n",
        "\n",
        "# visualize\n",
        "f,ax = plt.subplots(1,2, figsize=(10,5))\n",
        "ax[0].plot(xvalues, train_loss)\n",
        "ax[0].plot(xvalues, valid_loss)\n",
        "ax[0].set_title(\"Loss curve\")\n",
        "ax[0].set_xlabel(\"Epoch\")\n",
        "ax[0].set_ylabel(\"loss\")\n",
        "ax[0].legend(['train', 'validation'])\n",
        "\n",
        "ax[1].plot(xvalues, train_acc)\n",
        "ax[1].plot(xvalues, valid_acc)\n",
        "ax[1].set_title(\"Accuracy\")\n",
        "ax[1].set_xlabel(\"Epoch\")\n",
        "ax[1].set_ylabel(\"accuracy\")\n",
        "ax[1].legend(['train', 'validation'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-c6ec0c7f5879>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    let's plot the loss and accuracy\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEz_CuXfhswx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "4257cddd-0517-4587-cb30-90dbbc50219c"
      },
      "source": [
        "# What is the final loss and accuracy on our validation data?\n",
        "valid_loss, valid_acc = model.evaluate_generator(valid_data_gen, steps=nb_valid_steps)\n",
        "print(f\"Final validation accuracy: {valid_acc*100:.2f}%\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-5c57fb568b6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_valid_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Final validation accuracy: {valid_acc*100:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1715\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0maverages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstateful_metric_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             averages.append(np.average([out[i] for out in outs_per_batch],\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'outs' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3npnFtFhssF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD6X3pQQhsqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4xyAPY2hsna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbFeg3Bahslu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIBwiGtzhsjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sXeLuprhsed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x98QnEdzhsWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}